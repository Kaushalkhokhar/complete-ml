{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2478f555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c75ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f93bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5118d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPU's:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of available GPU's: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3d3bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\TheCompleteML\\\\projects'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if \"CNN\" in os.path.abspath(os.curdir): os.chdir(\"..\")\n",
    "BASE_DIR = os.path.abspath(os.curdir)\n",
    "BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2045ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(BASE_DIR, \"datasets\", \"classification\", \"flowers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756baa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\daisy',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\dandelion',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\rose',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\sunflower',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\tulip']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs = [os.path.join(data_dir, dir_) for dir_ in os.listdir(data_dir) if \"processed\" not in dir_]\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2038ee",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a74f9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage import io\n",
    "\n",
    "class loading_and_splitting:\n",
    "    \n",
    "    def __init__(self, data_dirs, dims, channels=3, target_dir=data_dir, split_count=10):\n",
    "        self.total_images = 0\n",
    "        self.minh = np.inf\n",
    "        self.minw = np.inf\n",
    "        self.dims = dims\n",
    "        self.channels = channels\n",
    "        self.target_dir = target_dir\n",
    "        self.split_count = split_count\n",
    "        self.data_dirs = data_dirs\n",
    "        self.class_map = {k:v.split(\"\\\\\")[-1] for k, v in enumerate(data_dirs)}\n",
    "        \n",
    "        self.header_list = [f\"x{i}\" for i in range(self.dims[0]*self.dims[1]*self.channels)] + [\"label\"]\n",
    "        self.sample_list = [random.sample(range(len(os.listdir(path))), \n",
    "                                          len(os.listdir(path))) for path in data_dirs]\n",
    "        for item in self.sample_list:\n",
    "            self.total_images += len(item)\n",
    "        self.generate_samples()\n",
    "        self.max_train_instance = len(self.train_seq)\n",
    "        self.max_valid_instance = len(self.valid_seq)\n",
    "        self.max_test_instance = len(self.test_seq)\n",
    "    \n",
    "    def generate_csvs(self):\n",
    "        header_list = [f\"x{i}\" for i in range(self.dims[0]*self.dims[1]*self.channels)] + [\"label\"]\n",
    "        for set_ in [\"train\", \"valid\", \"test\"]:\n",
    "            with open(os.path.join(self.target_dir, f\"{set_}.csv\"), \"w\") as f:\n",
    "                df = pd.DataFrame(list(), columns=header_list)\n",
    "                df.to_csv(f, index=False)\n",
    "                \n",
    "    def generate_samples(self):\n",
    "        self.sample_seq = random.sample(range(self.total_images), self.total_images)\n",
    "        self.train_seq = self.sample_seq[:int(len(self.sample_seq)*0.8)]\n",
    "        self.valid_seq = self.sample_seq[int(len(self.sample_seq)*0.8):int(len(self.sample_seq)*0.9)]\n",
    "        self.test_seq = self.sample_seq[int(len(self.sample_seq)*0.9):]\n",
    "    \n",
    "    def crop_image(self, image):\n",
    "        h, w, d = image.shape\n",
    "        if h >= self.minh and w >= self.minw:\n",
    "            image = image[int(h/2)-64:int(h/2)+64, \n",
    "                          int(w/2)-64:int(w/2)+64, \n",
    "                          :]\n",
    "            return image\n",
    "    \n",
    "    def crop_or_pad(self, image):\n",
    "        image = tf.image.resize_with_crop_or_pad(image, self.dims[0], self.dims[0])\n",
    "        return image.numpy()\n",
    "    \n",
    "    def shuffle_and_save(self):\n",
    "        empty = []\n",
    "        train = np.zeros((1, self.dims[0]*self.dims[1]*self.channels + 1))\n",
    "        valid = np.zeros((1, self.dims[0]*self.dims[1]*self.channels + 1))\n",
    "        test = np.zeros((1, self.dims[0]*self.dims[1]*self.channels + 1))\n",
    "        count = 0\n",
    "        while len(empty) != len(self.data_dirs):\n",
    "            sel_dir = np.random.randint(0, len(self.data_dirs))\n",
    "            if sel_dir in empty: continue\n",
    "            dir_ = self.data_dirs[sel_dir]\n",
    "            if not self.sample_list[sel_dir]:\n",
    "                empty.append(sel_dir)\n",
    "            else:\n",
    "                count += 1\n",
    "                print(f\"Processing: {count}\")\n",
    "                sel_image = self.sample_list[sel_dir].pop()\n",
    "                image = io.imread(os.path.join(dir_, os.listdir(dir_)[sel_image]))\n",
    "                \n",
    "                h, w, d = image.shape\n",
    "                if h < self.minh: self.minh = h\n",
    "                if w < self.minw: self.minw = w\n",
    "                if self.minh < self.dims[0]: self.minh = self.dims[0]\n",
    "                if self.minw < self.dims[1]: self.minw = self.dims[1]\n",
    "                \n",
    "                # image = self.crop_image(image)\n",
    "                image = self.crop_or_pad(image)\n",
    "                \n",
    "                if not isinstance(image, np.ndarray): continue\n",
    "                if sel_image in self.train_seq: \n",
    "                    train = np.append(train, np.append(image.flatten(), sel_dir).reshape(1,-1), axis=0)\n",
    "                elif sel_image in self.valid_seq: \n",
    "                    valid = np.append(valid, np.append(image.flatten(), sel_dir).reshape(1,-1), axis=0)\n",
    "                elif sel_image in self.test_seq: \n",
    "                    test = np.append(test, np.append(image.flatten(), sel_dir).reshape(1,-1), axis=0)\n",
    "        \n",
    "        train = train[1:, :]\n",
    "        valid = valid[1:, :]\n",
    "        test = test[1:, :]\n",
    "        \n",
    "        for prefix, arr in zip([\"train\", \"valid\", \"test\"], [train, valid, test]):\n",
    "            self.split_and_save(arr, os.path.join(self.target_dir, \"processed\", prefix), prefix)\n",
    "        \n",
    "    def split_and_save(self, arr, target_dir, prefix):\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        for i in range(self.split_count):\n",
    "            df = pd.DataFrame(arr[i*int(arr.shape[0]//self.split_count):(i+1)*int(arr.shape[0]//self.split_count), :], \n",
    "                             columns=self.header_list)\n",
    "            df.to_csv(os.path.join(target_dir, \"{}_{}.csv\".format(prefix, i+1)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36b3b1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'daisy', 1: 'dandelion', 2: 'rose', 3: 'sunflower', 4: 'tulip'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = (150, 150)\n",
    "channels = 3\n",
    "n_features = dims[0] * dims[1] * channels\n",
    "split_count = 10\n",
    "ls = loading_and_splitting(data_dirs=data_dirs, dims=dims, channels=channels, target_dir=data_dir, split_count=split_count)\n",
    "class_map = ls.class_map\n",
    "max_train_instance = (ls.max_train_instance//split_count)*split_count\n",
    "max_valid_instance = (ls.max_valid_instance//split_count)*split_count\n",
    "max_test_instance = (ls.max_test_instance//split_count)*split_count\n",
    "class_map\n",
    "# ls.shuffle_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff916084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3450, 430, 430)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_train_instance, max_valid_instance, max_test_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13cb128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dir = os.path.join(data_dir, \"processed\")\n",
    "train_paths = [f\"{os.path.join(set_dir, 'train')}\\\\{item}\" for item in os.listdir(os.path.join(set_dir, \"train\"))]\n",
    "valid_paths = [f\"{os.path.join(set_dir, 'valid')}\\\\{item}\" for item in os.listdir(os.path.join(set_dir, \"valid\"))]\n",
    "test_paths = [f\"{os.path.join(set_dir, 'test')}\\\\{item}\" for item in os.listdir(os.path.join(set_dir, \"test\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a461c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([keras.layers.RandomFlip(\"horizontal_and_vertical\"), \n",
    "                                         keras.layers.RandomRotation(0.2),\n",
    "                                         keras.layers.RandomContrast(0.5),\n",
    "                                         keras.layers.RandomZoom((-0.3, 0.3), (-0.3, 0.3))\n",
    "                                         ])\n",
    "\n",
    "def preprocess(line, augmentation=False):\n",
    "    defs = [tf.constant([], dtype = tf.float32)] * (n_features + 1)\n",
    "    xy = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    X = tf.stack(xy[:-1])\n",
    "    y = tf.stack(xy[-1:])\n",
    "    \n",
    "    # prcessing steps\n",
    "    X = tf.divide(X, 255)\n",
    "    X = tf.reshape(X, [dims[0], dims[1], channels])\n",
    "    if augmnentation:\n",
    "        X = data_augmentation(X)\n",
    "        X = tf.image.rot90(X)\n",
    "        X = tf.image.random_brightness(X, 0.2)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def preprocess_test(X):\n",
    "    # prcessing steps\n",
    "    \n",
    "    X = tf.image.resize_with_crop_or_pad(X, 150 ,150)\n",
    "    X = data_augmentation(X)\n",
    "    X = tf.image.rot90(X)\n",
    "    X = tf.image.random_brightness(X, 0.2)\n",
    "    X = tf.divide(X, 255)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b91d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def read_csv_pipeline(paths, \n",
    "                      n_readers, \n",
    "                      shuffle_buffer_size, \n",
    "                      n_read_threds, \n",
    "                      n_parse_threads, \n",
    "                      batch_size, \n",
    "                      augmentation=False):\n",
    "    \n",
    "    filepaths = tf.data.Dataset.list_files(paths, seed=42)\n",
    "    dataset = filepaths.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), cycle_length=n_readers)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    if augmentation: dataset = dataset.repeat()\n",
    "    dataset = dataset.map(partial(preprocess, augmentation=augmentation), num_parallel_calls=n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42529d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5\n",
    "shuffle_buffer_size = 400\n",
    "n_read_threads = None\n",
    "n_parse_threads = 5\n",
    "batch_size = 32\n",
    "\n",
    "train_set = read_csv_pipeline(train_paths, n_readers, \n",
    "                              n_repeat, shuffle_buffer_size, \n",
    "                              n_read_threads, n_parse_threads, \n",
    "                              batch_size, \n",
    "                              augmentation=True)\n",
    "\n",
    "valid_set = read_csv_pipeline(valid_paths, n_readers, \n",
    "                              n_repeat, shuffle_buffer_size, \n",
    "                              n_read_threads, n_parse_threads, \n",
    "                              batch_size, \n",
    "                              augmentation=False)\n",
    "\n",
    "test_set = read_csv_pipeline(test_paths, n_readers, \n",
    "                              n_repeat, shuffle_buffer_size, \n",
    "                              n_read_threads, n_parse_threads, \n",
    "                              batch_size, \n",
    "                              augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78754dc",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec68990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, fm, strides=1, ksize=3, padding=\"same\", activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fm = fm\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.normalization = keras.layers.BatchNormalization()\n",
    "        self.mainc_layers = [keras.layers.Conv2D(self.fm, \n",
    "                                                 kernel_size=self.ksize, \n",
    "                                                 strides=self.strides, \n",
    "                                                 padding=self.padding, \n",
    "                                                 use_bias=False),\n",
    "                            self.normalization, \n",
    "                            self.activation,\n",
    "                            keras.layers.Conv2D(self.fm, \n",
    "                                                kernel_size=self.ksize, \n",
    "                                                strides=1, \n",
    "                                                padding=self.padding, \n",
    "                                                use_bias=False),\n",
    "                            self.normalization]\n",
    "        self.skipc_layers = []\n",
    "        if strides > 1:\n",
    "            self.skipc_layers = [keras.layers.Conv2D(self.fm, \n",
    "                                                     kernel_size=1, \n",
    "                                                     strides=self.strides, \n",
    "                                                     padding=self.padding,\n",
    "                                                     use_bias=False),\n",
    "                                self.normalization]\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"fm\": self.fm,\n",
    "                        \"ksize\": self.ksize,\n",
    "                        \"strides\": self.strides,\n",
    "                        \"padding\": self.padding,\n",
    "                        \"activation\": self.activation\n",
    "                        })\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z = inputs\n",
    "        for layer in self.mainc_layers:\n",
    "            z = layer(z)\n",
    "        skip_z = inputs\n",
    "        for layer in self.skipc_layers:\n",
    "            skip_z = layer(skip_z)\n",
    "        return self.activation(z+skip_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6981d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes: dense layer size increased to 128\n",
    "             he_normal initilizatin is implemented\n",
    "             optimizer is changed from nadam to momentum with decay rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a52c89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a762691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1814 - val_loss: nan - val_sparse_categorical_accuracy: 0.1719\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1843 - val_loss: nan - val_sparse_categorical_accuracy: 0.1771\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1775 - val_loss: nan - val_sparse_categorical_accuracy: 0.1719\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 132s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1611 - val_loss: nan - val_sparse_categorical_accuracy: 0.1667\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1817 - val_loss: nan - val_sparse_categorical_accuracy: 0.1693\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a6cc8",
   "metadata": {},
   "source": [
    "### Training with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07536d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "   \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "#     optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"nadam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86bbd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbc14f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 138s 1s/step - loss: 1.4514 - sparse_categorical_accuracy: 0.3553 - val_loss: 1.2857 - val_sparse_categorical_accuracy: 0.3854\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 137s 1s/step - loss: 1.3074 - sparse_categorical_accuracy: 0.4446 - val_loss: 1.3003 - val_sparse_categorical_accuracy: 0.4089\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.2394 - sparse_categorical_accuracy: 0.4726 - val_loss: 1.1672 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.2192 - sparse_categorical_accuracy: 0.5200 - val_loss: 1.1271 - val_sparse_categorical_accuracy: 0.5807\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 132s 1s/step - loss: 1.1396 - sparse_categorical_accuracy: 0.5467 - val_loss: 1.0547 - val_sparse_categorical_accuracy: 0.5781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "097ca5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "  \n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8201896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9ba9d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 136s 1s/step - loss: 1.6377 - sparse_categorical_accuracy: 0.2574 - val_loss: 1.6638 - val_sparse_categorical_accuracy: 0.1745\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.6141 - sparse_categorical_accuracy: 0.2378 - val_loss: 1.6102 - val_sparse_categorical_accuracy: 0.2474\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.6052 - sparse_categorical_accuracy: 0.2239 - val_loss: 1.5973 - val_sparse_categorical_accuracy: 0.2474\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.5893 - sparse_categorical_accuracy: 0.2610 - val_loss: 1.5938 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 5/5\n",
      "54/97 [===============>..............] - ETA: 43s - loss: 1.6123 - sparse_categorical_accuracy: 0.1921"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4976/1190883073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(train_set, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_train_instance\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_valid_instance\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64ba3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1c6044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "499fcc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 136s 1s/step - loss: 1.4953 - sparse_categorical_accuracy: 0.3283 - val_loss: 1.3413 - val_sparse_categorical_accuracy: 0.3750\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.3042 - sparse_categorical_accuracy: 0.4288 - val_loss: 1.2589 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 131s 1s/step - loss: 1.2657 - sparse_categorical_accuracy: 0.4555 - val_loss: 1.1900 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.2398 - sparse_categorical_accuracy: 0.4771 - val_loss: 1.1691 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 131s 1s/step - loss: 1.2400 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.1564 - val_sparse_categorical_accuracy: 0.5130\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88513ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "  \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c82d0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab9c69be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.5109 - sparse_categorical_accuracy: 0.3070 - val_loss: 1.2921 - val_sparse_categorical_accuracy: 0.3828\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 128s 1s/step - loss: 1.3329 - sparse_categorical_accuracy: 0.4162 - val_loss: 1.2634 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 131s 1s/step - loss: 1.3028 - sparse_categorical_accuracy: 0.4265 - val_loss: 1.2135 - val_sparse_categorical_accuracy: 0.4453\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.2508 - sparse_categorical_accuracy: 0.4671 - val_loss: 1.1935 - val_sparse_categorical_accuracy: 0.4870\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.1902 - sparse_categorical_accuracy: 0.5061 - val_loss: 1.1198 - val_sparse_categorical_accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "825be59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes: dense layer size increased to 128\n",
    "             he_normal initilizatin is implemented\n",
    "             optimizer is changed from nadam to momentum with decay rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d17554f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa4a74fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.4417 - sparse_categorical_accuracy: 0.3531 - val_loss: 1.2625 - val_sparse_categorical_accuracy: 0.4245\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 129s 1s/step - loss: 1.2789 - sparse_categorical_accuracy: 0.4433 - val_loss: 1.1716 - val_sparse_categorical_accuracy: 0.4609\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 129s 1s/step - loss: 1.2445 - sparse_categorical_accuracy: 0.4768 - val_loss: 1.1711 - val_sparse_categorical_accuracy: 0.5052\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 132s 1s/step - loss: 1.2316 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1175 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.1931 - sparse_categorical_accuracy: 0.4987 - val_loss: 1.0944 - val_sparse_categorical_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98646324",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes: dense layer size increased to 128\n",
    "             he_normal initilizatin is implemented\n",
    "             optimizer is changed from nadam to momentum with decay rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "febf7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fc8f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 145s 1s/step - loss: 1.4900 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.2772 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 139s 1s/step - loss: 1.3380 - sparse_categorical_accuracy: 0.4214 - val_loss: 1.2705 - val_sparse_categorical_accuracy: 0.3854\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 139s 1s/step - loss: 1.2860 - sparse_categorical_accuracy: 0.4681 - val_loss: 1.2057 - val_sparse_categorical_accuracy: 0.5208\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 135s 1s/step - loss: 1.2318 - sparse_categorical_accuracy: 0.4974 - val_loss: 1.1199 - val_sparse_categorical_accuracy: 0.5260\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.2226 - sparse_categorical_accuracy: 0.5084 - val_loss: 1.1106 - val_sparse_categorical_accuracy: 0.5755\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df609df",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "Above results clearly concludes that nadam and RMSprop optimizer outperforms all others. Next, we can choose nadam.RMSprop and experiments with some other variables with model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397e4b1",
   "metadata": {},
   "source": [
    "## Different Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a80756fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r4_de():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes copare to cnn_mp_r3_de:\n",
    "            extra cnn with kenel size of 512\n",
    "            dense layer size increased to 128\n",
    "            he_normal initilizatin is implemented\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(512, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"nadam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "        \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r4_de.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c578a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r4_de()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd3fc98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 155s 2s/step - loss: 1.6924 - sparse_categorical_accuracy: 0.3254 - val_loss: 1.3802 - val_sparse_categorical_accuracy: 0.3776\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 151s 2s/step - loss: 1.3186 - sparse_categorical_accuracy: 0.4166 - val_loss: 1.2118 - val_sparse_categorical_accuracy: 0.4401\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 156s 2s/step - loss: 1.2511 - sparse_categorical_accuracy: 0.4720 - val_loss: 1.1742 - val_sparse_categorical_accuracy: 0.5104\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 155s 2s/step - loss: 1.2143 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.1436 - val_sparse_categorical_accuracy: 0.5052\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.1657 - sparse_categorical_accuracy: 0.5245 - val_loss: 1.0710 - val_sparse_categorical_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bdf0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes:\n",
    "            dense layer size increased to 128\n",
    "            he_normal initilizatin is implemented\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"nadam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "        \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12e518a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cbecf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 144s 1s/step - loss: 1.7884 - sparse_categorical_accuracy: 0.3541 - val_loss: 1.2552 - val_sparse_categorical_accuracy: 0.4531\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 139s 1s/step - loss: 1.2972 - sparse_categorical_accuracy: 0.4443 - val_loss: 1.1778 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 138s 1s/step - loss: 1.2268 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.1302 - val_sparse_categorical_accuracy: 0.5495\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.1826 - sparse_categorical_accuracy: 0.4971 - val_loss: 1.0885 - val_sparse_categorical_accuracy: 0.5521\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 143s 1s/step - loss: 1.1258 - sparse_categorical_accuracy: 0.5506 - val_loss: 1.0160 - val_sparse_categorical_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51f63c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "97/97 [==============================] - 147s 2s/step - loss: 1.7125 - sparse_categorical_accuracy: 0.3576 - val_loss: 1.2798 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 2/25\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.3085 - sparse_categorical_accuracy: 0.4391 - val_loss: 1.2109 - val_sparse_categorical_accuracy: 0.4740\n",
      "Epoch 3/25\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.2280 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.2233 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 4/25\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.2010 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.0990 - val_sparse_categorical_accuracy: 0.5677\n",
      "Epoch 5/25\n",
      "97/97 [==============================] - 136s 1s/step - loss: 1.1398 - sparse_categorical_accuracy: 0.5370 - val_loss: 1.0768 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 6/25\n",
      "97/97 [==============================] - 135s 1s/step - loss: 1.1281 - sparse_categorical_accuracy: 0.5522 - val_loss: 1.0613 - val_sparse_categorical_accuracy: 0.5729\n",
      "Epoch 7/25\n",
      "97/97 [==============================] - 137s 1s/step - loss: 1.0861 - sparse_categorical_accuracy: 0.5660 - val_loss: 1.0771 - val_sparse_categorical_accuracy: 0.5443\n",
      "Epoch 8/25\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.0461 - sparse_categorical_accuracy: 0.5889 - val_loss: 1.0003 - val_sparse_categorical_accuracy: 0.6172\n",
      "Epoch 9/25\n",
      "79/97 [=======================>......] - ETA: 17s - loss: 1.0235 - sparse_categorical_accuracy: 0.5989WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2425 batches). You may need to use the repeat() function when building your dataset.\n",
      "97/97 [==============================] - 113s 1s/step - loss: 1.0235 - sparse_categorical_accuracy: 0.5989 - val_loss: 0.9657 - val_sparse_categorical_accuracy: 0.5911\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=25, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ed225",
   "metadata": {},
   "source": [
    "##### Note\n",
    "\n",
    "Done necessary adjustement to max_instances and steps_per_epochs to supress the warning message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d648c",
   "metadata": {},
   "source": [
    "### Experiment with Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "157d5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr*self.factor)\n",
    "        \n",
    "def find_learnig_rate(model, train_set, epochs=1, batch_size=32, min_rate=1e-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    iterations = np.math.ceil(0.85 * max_train_instance / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(train_set, \n",
    "                        epochs=epochs, \n",
    "                        steps_per_epoch=int(0.85 * max_train_instance / batch_size),\n",
    "                        batch_size=batch_size, \n",
    "                        callbacks=[exp_lr])\n",
    "    model.set_weights(init_weights)\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_rates_vs_losses(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd52b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70d459d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7635ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "91/91 [==============================] - 96s 1s/step - loss: 3085.5239 - sparse_categorical_accuracy: 0.2294\n",
      "Epoch 2/2\n",
      "91/91 [==============================] - 95s 1s/step - loss: 95.5725 - sparse_categorical_accuracy: 0.2215\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "rates, losses = find_learnig_rate(model, train_set, epochs=2, batch_size=batch_size)\n",
    "plot_rates_vs_losses(rates, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ec110",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "From the above graph we can set the max learning rate to arroud 0.8 for 1cycle scheduling aproch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56d646",
   "metadata": {},
   "source": [
    "#### Applying the one cycle aproch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f32e2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()\n",
    "\n",
    "steps_factor = 0.85\n",
    "epochs = 5\n",
    "max_learning_rate = 0.8\n",
    "one_cycle_cb = OneCycleScheduler(int(steps_factor * max_train_instance / batch_size) * epochs, max_rate=max_learning_rate)\n",
    "\n",
    "callbacks.append(one_cycle_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae77974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "91/91 [==============================] - 228s 3s/step - loss: 11959.7666 - sparse_categorical_accuracy: 0.2119 - val_loss: 1.6336 - val_sparse_categorical_accuracy: 0.2392\n",
      "Epoch 2/5\n",
      "91/91 [==============================] - 226s 3s/step - loss: 1.6242 - sparse_categorical_accuracy: 0.2157 - val_loss: 1.6138 - val_sparse_categorical_accuracy: 0.1791\n",
      "Epoch 3/5\n",
      "91/91 [==============================] - 222s 2s/step - loss: 1.6184 - sparse_categorical_accuracy: 0.2648 - val_loss: 1.6402 - val_sparse_categorical_accuracy: 0.2512\n",
      "Epoch 4/5\n",
      "91/91 [==============================] - 224s 2s/step - loss: 1.6072 - sparse_categorical_accuracy: 0.2438 - val_loss: 1.6235 - val_sparse_categorical_accuracy: 0.2512\n",
      "Epoch 5/5\n",
      "91/91 [==============================] - 224s 2s/step - loss: 1.6118 - sparse_categorical_accuracy: 0.2047 - val_loss: 1.6033 - val_sparse_categorical_accuracy: 0.2512\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=epochs, \n",
    "                    steps_per_epoch=int(steps_factor * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04f649ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()\n",
    "\n",
    "steps_factor = 0.85\n",
    "epochs = 5\n",
    "max_learning_rate = 1.2\n",
    "one_cycle_cb = OneCycleScheduler(int(steps_factor * max_train_instance / batch_size) * epochs, max_rate=max_learning_rate)\n",
    "\n",
    "callbacks.append(one_cycle_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8bdc188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "91/91 [==============================] - 227s 2s/step - loss: 12666506.0000 - sparse_categorical_accuracy: 0.2376 - val_loss: 197.1367 - val_sparse_categorical_accuracy: 0.2509\n",
      "Epoch 2/5\n",
      "91/91 [==============================] - 225s 2s/step - loss: 33.2915 - sparse_categorical_accuracy: 0.2242 - val_loss: 1.6751 - val_sparse_categorical_accuracy: 0.2512\n",
      "Epoch 3/5\n",
      "91/91 [==============================] - 225s 2s/step - loss: 1.6692 - sparse_categorical_accuracy: 0.2294 - val_loss: 1.6285 - val_sparse_categorical_accuracy: 0.2395\n",
      "Epoch 4/5\n",
      "91/91 [==============================] - 223s 2s/step - loss: 1.6642 - sparse_categorical_accuracy: 0.2291 - val_loss: 1.6160 - val_sparse_categorical_accuracy: 0.1791\n",
      "Epoch 5/5\n",
      "91/91 [==============================] - 224s 2s/step - loss: 1.5953 - sparse_categorical_accuracy: 0.2473 - val_loss: 1.5978 - val_sparse_categorical_accuracy: 0.2512\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=epochs, \n",
    "                    steps_per_epoch=int(steps_factor * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4ab3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
