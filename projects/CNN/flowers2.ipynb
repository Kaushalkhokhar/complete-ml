{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc20a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbc4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a7bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1c843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPU's:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of available GPU's: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbdeebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\TheCompleteML\\\\projects'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if \"CNN\" in os.path.abspath(os.curdir): os.chdir(\"..\")\n",
    "BASE_DIR = os.path.abspath(os.curdir)\n",
    "BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b72058",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(BASE_DIR, \"datasets\", \"classification\", \"flowers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a3620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\daisy',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\dandelion',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\rose',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\sunflower',\n",
       " 'D:\\\\TheCompleteML\\\\projects\\\\datasets\\\\classification\\\\flowers\\\\tulip']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs = [os.path.join(data_dir, dir_) for dir_ in os.listdir(data_dir) if \"processed\" not in dir_]\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5342d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa57ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage import io\n",
    "\n",
    "class loading_and_splitting:\n",
    "    \n",
    "    def __init__(self, data_dirs, dims, channels=3, target_dir=data_dir):\n",
    "        self.total_images = 0\n",
    "        self.minh = np.inf\n",
    "        self.minw = np.inf\n",
    "        self.dims = dims\n",
    "        self.channels = channels\n",
    "        self.target_dir = target_dir\n",
    "        self.data_dirs = data_dirs\n",
    "        self.class_map = {k:v.split(\"\\\\\")[-1] for k, v in enumerate(data_dirs)}\n",
    "        \n",
    "        self.header_list = [f\"x{i}\" for i in range(self.dims[0]*self.dims[1]*self.channels)] + [\"label\"]\n",
    "        self.sample_list = [random.sample(range(len(os.listdir(path))), \n",
    "                                          len(os.listdir(path))) for path in data_dirs]\n",
    "        for item in self.sample_list:\n",
    "            self.total_images += len(item)\n",
    "        self.generate_samples()\n",
    "        self.max_train_instance = len(self.train_seq)\n",
    "        self.max_valid_instance = len(self.valid_seq)\n",
    "        self.max_test_instance = len(self.test_seq)\n",
    "    \n",
    "    def generate_csvs(self):\n",
    "        header_list = [f\"x{i}\" for i in range(self.dims[0]*self.dims[1]*self.channels)] + [\"label\"]\n",
    "        for set_ in [\"train\", \"valid\", \"test\"]:\n",
    "            with open(os.path.join(self.target_dir, f\"{set_}.csv\"), \"w\") as f:\n",
    "                df = pd.DataFrame(list(), columns=header_list)\n",
    "                df.to_csv(f, index=False)\n",
    "                \n",
    "    def generate_samples(self):\n",
    "        self.sample_seq = random.sample(range(self.total_images), self.total_images)\n",
    "        self.train_seq = self.sample_seq[:int(len(self.sample_seq)*0.8)]\n",
    "        self.valid_seq = self.sample_seq[int(len(self.sample_seq)*0.8):int(len(self.sample_seq)*0.9)]\n",
    "        self.test_seq = self.sample_seq[int(len(self.sample_seq)*0.9):]\n",
    "    \n",
    "    def crop_image(self, image):\n",
    "        h, w, d = image.shape\n",
    "        if h >= self.minh and w >= self.minw:\n",
    "            image = image[int(h/2)-64:int(h/2)+64, \n",
    "                          int(w/2)-64:int(w/2)+64, \n",
    "                          :]\n",
    "            return image\n",
    "    \n",
    "    def crop_or_pad(self, image):\n",
    "        image = tf.image.resize_with_crop_or_pad(image, self.dims[0], self.dims[0])\n",
    "        return image.numpy()\n",
    "    \n",
    "    def shuffle_and_save(self):\n",
    "        empty = []\n",
    "        train = np.zeros((1, self.dims[0]*self.dims[1]*self.channels + 1))\n",
    "        valid = np.zeros((1, self.dims[0]*self.dims[1]*self.channels + 1))\n",
    "        test = np.zeros((1, self.dims[0]*self.dims[1]*self.channels + 1))\n",
    "        count = 0\n",
    "        while len(empty) != len(self.data_dirs):\n",
    "            sel_dir = np.random.randint(0, len(self.data_dirs))\n",
    "            if sel_dir in empty: continue\n",
    "            dir_ = self.data_dirs[sel_dir]\n",
    "            if not self.sample_list[sel_dir]:\n",
    "                empty.append(sel_dir)\n",
    "            else:\n",
    "                count += 1\n",
    "                print(f\"Processing: {count}\")\n",
    "                sel_image = self.sample_list[sel_dir].pop()\n",
    "                image = io.imread(os.path.join(dir_, os.listdir(dir_)[sel_image]))\n",
    "                \n",
    "                h, w, d = image.shape\n",
    "                if h < self.minh: self.minh = h\n",
    "                if w < self.minw: self.minw = w\n",
    "                if self.minh < self.dims[0]: self.minh = self.dims[0]\n",
    "                if self.minw < self.dims[1]: self.minw = self.dims[1]\n",
    "                \n",
    "                # image = self.crop_image(image)\n",
    "                image = self.crop_or_pad(image)\n",
    "                \n",
    "                if not isinstance(image, np.ndarray): continue\n",
    "                if sel_image in self.train_seq: \n",
    "                    train = np.append(train, np.append(image.flatten(), sel_dir).reshape(1,-1), axis=0)\n",
    "                elif sel_image in self.valid_seq: \n",
    "                    valid = np.append(valid, np.append(image.flatten(), sel_dir).reshape(1,-1), axis=0)\n",
    "                elif sel_image in self.test_seq: \n",
    "                    test = np.append(test, np.append(image.flatten(), sel_dir).reshape(1,-1), axis=0)\n",
    "        \n",
    "        train = train[1:, :]\n",
    "        valid = valid[1:, :]\n",
    "        test = test[1:, :]\n",
    "        \n",
    "        for prefix, arr in zip([\"train\", \"valid\", \"test\"], [train, valid, test]):\n",
    "            self.split_and_save(arr, os.path.join(self.target_dir, \"processed\", prefix), prefix)\n",
    "        \n",
    "    def split_and_save(self, arr, target_dir, prefix, split_count=10):\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        for i in range(split_count):\n",
    "            df = pd.DataFrame(arr[i*int(arr.shape[0]//split_count):(i+1)*int(arr.shape[0]//split_count), :], \n",
    "                             columns=self.header_list)\n",
    "            df.to_csv(os.path.join(target_dir, \"{}_{}.csv\".format(prefix, i+1)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f922cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'daisy', 1: 'dandelion', 2: 'rose', 3: 'sunflower', 4: 'tulip'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = (150, 150)\n",
    "channels = 3\n",
    "n_features = dims[0] * dims[1] * channels\n",
    "ls = loading_and_splitting(data_dirs=data_dirs, dims=dims, channels=channels, target_dir=data_dir)\n",
    "class_map = ls.class_map\n",
    "max_train_instance = ls.max_train_instance\n",
    "max_valid_instance = ls.max_valid_instance\n",
    "max_test_instance = ls.max_test_instance\n",
    "class_map\n",
    "# ls.shuffle_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7378845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3453, 432, 432)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_train_instance, max_valid_instance, max_test_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca43f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dir = os.path.join(data_dir, \"processed\")\n",
    "train_paths = [f\"{os.path.join(set_dir, 'train')}\\\\{item}\" for item in os.listdir(os.path.join(set_dir, \"train\"))]\n",
    "valid_paths = [f\"{os.path.join(set_dir, 'valid')}\\\\{item}\" for item in os.listdir(os.path.join(set_dir, \"valid\"))]\n",
    "test_paths = [f\"{os.path.join(set_dir, 'test')}\\\\{item}\" for item in os.listdir(os.path.join(set_dir, \"test\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489698a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([keras.layers.RandomFlip(\"horizontal_and_vertical\"), \n",
    "                                         keras.layers.RandomRotation(0.2),\n",
    "                                         keras.layers.RandomContrast(0.5),\n",
    "                                         keras.layers.RandomZoom((-0.3, 0.3), (-0.3, 0.3))\n",
    "                                         ])\n",
    "\n",
    "def preprocess(line, augmentation=False):\n",
    "    defs = [tf.constant([], dtype = tf.float32)] * (n_features + 1)\n",
    "    xy = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    X = tf.stack(xy[:-1])\n",
    "    y = tf.stack(xy[-1:])\n",
    "    \n",
    "    # prcessing steps\n",
    "    X = tf.divide(X, 255)\n",
    "    X = tf.reshape(X, [dims[0], dims[1], channels])\n",
    "    if augmnentation:\n",
    "        X = data_augmentation(X)\n",
    "        X = tf.image.rot90(X)\n",
    "        X = tf.image.random_brightness(X, 0.2)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def preprocess_test(X):\n",
    "    # prcessing steps\n",
    "    \n",
    "    X = tf.image.resize_with_crop_or_pad(X, 150 ,150)\n",
    "    X = data_augmentation(X)\n",
    "    X = tf.image.rot90(X)\n",
    "    X = tf.image.random_brightness(X, 0.2)\n",
    "    X = tf.divide(X, 255)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d841f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def read_csv_pipeline(paths, \n",
    "                      n_readers, \n",
    "                      shuffle_buffer_size, \n",
    "                      n_read_threds, \n",
    "                      n_parse_threads, \n",
    "                      batch_size, \n",
    "                      augmentation=False):\n",
    "    \n",
    "    filepaths = tf.data.Dataset.list_files(paths, seed=42)\n",
    "    dataset = filepaths.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), cycle_length=n_readers)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    if augmentation: dataset = dataset.repeat()\n",
    "    dataset = dataset.map(partial(preprocess, augmentation=augmentation), num_parallel_calls=n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d77b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5\n",
    "shuffle_buffer_size = 400\n",
    "n_read_threads = None\n",
    "n_parse_threads = 5\n",
    "batch_size = 32\n",
    "\n",
    "train_set = read_csv_pipeline(train_paths, n_readers, \n",
    "                              n_repeat, shuffle_buffer_size, \n",
    "                              n_read_threads, n_parse_threads, \n",
    "                              batch_size, \n",
    "                              augmentation=True)\n",
    "\n",
    "valid_set = read_csv_pipeline(valid_paths, n_readers, \n",
    "                              n_repeat, shuffle_buffer_size, \n",
    "                              n_read_threads, n_parse_threads, \n",
    "                              batch_size, \n",
    "                              augmentation=False)\n",
    "\n",
    "test_set = read_csv_pipeline(test_paths, n_readers, \n",
    "                              n_repeat, shuffle_buffer_size, \n",
    "                              n_read_threads, n_parse_threads, \n",
    "                              batch_size, \n",
    "                              augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7207657",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08cb867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, fm, strides=1, ksize=3, padding=\"same\", activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fm = fm\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.normalization = keras.layers.BatchNormalization()\n",
    "        self.mainc_layers = [keras.layers.Conv2D(self.fm, \n",
    "                                                 kernel_size=self.ksize, \n",
    "                                                 strides=self.strides, \n",
    "                                                 padding=self.padding, \n",
    "                                                 use_bias=False),\n",
    "                            self.normalization, \n",
    "                            self.activation,\n",
    "                            keras.layers.Conv2D(self.fm, \n",
    "                                                kernel_size=self.ksize, \n",
    "                                                strides=1, \n",
    "                                                padding=self.padding, \n",
    "                                                use_bias=False),\n",
    "                            self.normalization]\n",
    "        self.skipc_layers = []\n",
    "        if strides > 1:\n",
    "            self.skipc_layers = [keras.layers.Conv2D(self.fm, \n",
    "                                                     kernel_size=1, \n",
    "                                                     strides=self.strides, \n",
    "                                                     padding=self.padding,\n",
    "                                                     use_bias=False),\n",
    "                                self.normalization]\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"fm\": self.fm,\n",
    "                        \"ksize\": self.ksize,\n",
    "                        \"strides\": self.strides,\n",
    "                        \"padding\": self.padding,\n",
    "                        \"activation\": self.activation\n",
    "                        })\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z = inputs\n",
    "        for layer in self.mainc_layers:\n",
    "            z = layer(z)\n",
    "        skip_z = inputs\n",
    "        for layer in self.skipc_layers:\n",
    "            skip_z = layer(skip_z)\n",
    "        return self.activation(z+skip_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a24a8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes: dense layer size increased to 128\n",
    "             he_normal initilizatin is implemented\n",
    "             optimizer is changed from nadam to momentum with decay rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "985b2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01d65776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1814 - val_loss: nan - val_sparse_categorical_accuracy: 0.1719\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1843 - val_loss: nan - val_sparse_categorical_accuracy: 0.1771\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1775 - val_loss: nan - val_sparse_categorical_accuracy: 0.1719\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 132s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1611 - val_loss: nan - val_sparse_categorical_accuracy: 0.1667\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: nan - sparse_categorical_accuracy: 0.1817 - val_loss: nan - val_sparse_categorical_accuracy: 0.1693\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747798e",
   "metadata": {},
   "source": [
    "### Training with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfdbf712",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "   \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "#     optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"nadam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75339b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dec5a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 138s 1s/step - loss: 1.4514 - sparse_categorical_accuracy: 0.3553 - val_loss: 1.2857 - val_sparse_categorical_accuracy: 0.3854\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 137s 1s/step - loss: 1.3074 - sparse_categorical_accuracy: 0.4446 - val_loss: 1.3003 - val_sparse_categorical_accuracy: 0.4089\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.2394 - sparse_categorical_accuracy: 0.4726 - val_loss: 1.1672 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.2192 - sparse_categorical_accuracy: 0.5200 - val_loss: 1.1271 - val_sparse_categorical_accuracy: 0.5807\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 132s 1s/step - loss: 1.1396 - sparse_categorical_accuracy: 0.5467 - val_loss: 1.0547 - val_sparse_categorical_accuracy: 0.5781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d04e6348",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "  \n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92eb94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f578aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 136s 1s/step - loss: 1.6377 - sparse_categorical_accuracy: 0.2574 - val_loss: 1.6638 - val_sparse_categorical_accuracy: 0.1745\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.6141 - sparse_categorical_accuracy: 0.2378 - val_loss: 1.6102 - val_sparse_categorical_accuracy: 0.2474\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.6052 - sparse_categorical_accuracy: 0.2239 - val_loss: 1.5973 - val_sparse_categorical_accuracy: 0.2474\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.5893 - sparse_categorical_accuracy: 0.2610 - val_loss: 1.5938 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 5/5\n",
      "54/97 [===============>..............] - ETA: 43s - loss: 1.6123 - sparse_categorical_accuracy: 0.1921"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4976/1190883073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(train_set, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_train_instance\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_valid_instance\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TheCompleteML\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bc4e527",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.01)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aff9fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14108bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 136s 1s/step - loss: 1.4953 - sparse_categorical_accuracy: 0.3283 - val_loss: 1.3413 - val_sparse_categorical_accuracy: 0.3750\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.3042 - sparse_categorical_accuracy: 0.4288 - val_loss: 1.2589 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 131s 1s/step - loss: 1.2657 - sparse_categorical_accuracy: 0.4555 - val_loss: 1.1900 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.2398 - sparse_categorical_accuracy: 0.4771 - val_loss: 1.1691 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 131s 1s/step - loss: 1.2400 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.1564 - val_sparse_categorical_accuracy: 0.5130\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9b8005e",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "  \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f16b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bef3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.5109 - sparse_categorical_accuracy: 0.3070 - val_loss: 1.2921 - val_sparse_categorical_accuracy: 0.3828\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 128s 1s/step - loss: 1.3329 - sparse_categorical_accuracy: 0.4162 - val_loss: 1.2634 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 131s 1s/step - loss: 1.3028 - sparse_categorical_accuracy: 0.4265 - val_loss: 1.2135 - val_sparse_categorical_accuracy: 0.4453\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.2508 - sparse_categorical_accuracy: 0.4671 - val_loss: 1.1935 - val_sparse_categorical_accuracy: 0.4870\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.1902 - sparse_categorical_accuracy: 0.5061 - val_loss: 1.1198 - val_sparse_categorical_accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "449d654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes: dense layer size increased to 128\n",
    "             he_normal initilizatin is implemented\n",
    "             optimizer is changed from nadam to momentum with decay rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a72879b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f0dcbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.4417 - sparse_categorical_accuracy: 0.3531 - val_loss: 1.2625 - val_sparse_categorical_accuracy: 0.4245\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 129s 1s/step - loss: 1.2789 - sparse_categorical_accuracy: 0.4433 - val_loss: 1.1716 - val_sparse_categorical_accuracy: 0.4609\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 129s 1s/step - loss: 1.2445 - sparse_categorical_accuracy: 0.4768 - val_loss: 1.1711 - val_sparse_categorical_accuracy: 0.5052\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 132s 1s/step - loss: 1.2316 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1175 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 130s 1s/step - loss: 1.1931 - sparse_categorical_accuracy: 0.4987 - val_loss: 1.0944 - val_sparse_categorical_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bf6378a",
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes: dense layer size increased to 128\n",
    "             he_normal initilizatin is implemented\n",
    "             optimizer is changed from nadam to momentum with decay rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "    \n",
    "    \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a0a94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d54ead09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 145s 1s/step - loss: 1.4900 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.2772 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 139s 1s/step - loss: 1.3380 - sparse_categorical_accuracy: 0.4214 - val_loss: 1.2705 - val_sparse_categorical_accuracy: 0.3854\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 139s 1s/step - loss: 1.2860 - sparse_categorical_accuracy: 0.4681 - val_loss: 1.2057 - val_sparse_categorical_accuracy: 0.5208\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 135s 1s/step - loss: 1.2318 - sparse_categorical_accuracy: 0.4974 - val_loss: 1.1199 - val_sparse_categorical_accuracy: 0.5260\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.2226 - sparse_categorical_accuracy: 0.5084 - val_loss: 1.1106 - val_sparse_categorical_accuracy: 0.5755\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1bb19",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "Above results clearly concludes that nadam and RMSprop optimizer outperforms all others. Next, we can choose nadam.RMSprop and experiments with some other variables with model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04464817",
   "metadata": {},
   "source": [
    "## Different Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b09af6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r4_de():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes copare to cnn_mp_r3_de:\n",
    "            extra cnn with kenel size of 512\n",
    "            dense layer size increased to 128\n",
    "            he_normal initilizatin is implemented\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(512, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"nadam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "        \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r4_de.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b2c0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r4_de()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6db2bfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 155s 2s/step - loss: 1.6924 - sparse_categorical_accuracy: 0.3254 - val_loss: 1.3802 - val_sparse_categorical_accuracy: 0.3776\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 151s 2s/step - loss: 1.3186 - sparse_categorical_accuracy: 0.4166 - val_loss: 1.2118 - val_sparse_categorical_accuracy: 0.4401\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 156s 2s/step - loss: 1.2511 - sparse_categorical_accuracy: 0.4720 - val_loss: 1.1742 - val_sparse_categorical_accuracy: 0.5104\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 155s 2s/step - loss: 1.2143 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.1436 - val_sparse_categorical_accuracy: 0.5052\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 150s 2s/step - loss: 1.1657 - sparse_categorical_accuracy: 0.5245 - val_loss: 1.0710 - val_sparse_categorical_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5643636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def cnn_mp_r3_de_v2():\n",
    "    \"\"\"\n",
    "    name ecodes the model architecture\n",
    "    cnn followed by max pooling repeated three times, followed by dense layer\n",
    "    changes:\n",
    "            dense layer size increased to 128\n",
    "            he_normal initilizatin is implemented\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=5, \n",
    "                                  strides=2, padding=\"same\", \n",
    "                                  use_bias=False, \n",
    "                                  input_shape=[dims[0], dims[0], channels],\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size=3, \n",
    "                                  strides=1, padding=\"same\", \n",
    "                                  use_bias=False,\n",
    "                                  kernel_initializer=\"he_normal\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=\"nadam\", \n",
    "                  metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "        \n",
    "    model_target = os.path.join(BASE_DIR, \"models\", \"cnn_mp_r3_de_v2.h5\")\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(model_target, save_best_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = [checkpoint_cb, early_stop_cb]\n",
    "    \n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2a31bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = cnn_mp_r3_de_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bc7283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 144s 1s/step - loss: 1.7884 - sparse_categorical_accuracy: 0.3541 - val_loss: 1.2552 - val_sparse_categorical_accuracy: 0.4531\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 139s 1s/step - loss: 1.2972 - sparse_categorical_accuracy: 0.4443 - val_loss: 1.1778 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 138s 1s/step - loss: 1.2268 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.1302 - val_sparse_categorical_accuracy: 0.5495\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.1826 - sparse_categorical_accuracy: 0.4971 - val_loss: 1.0885 - val_sparse_categorical_accuracy: 0.5521\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 143s 1s/step - loss: 1.1258 - sparse_categorical_accuracy: 0.5506 - val_loss: 1.0160 - val_sparse_categorical_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5bc4148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "97/97 [==============================] - 147s 2s/step - loss: 1.7125 - sparse_categorical_accuracy: 0.3576 - val_loss: 1.2798 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 2/25\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.3085 - sparse_categorical_accuracy: 0.4391 - val_loss: 1.2109 - val_sparse_categorical_accuracy: 0.4740\n",
      "Epoch 3/25\n",
      "97/97 [==============================] - 141s 1s/step - loss: 1.2280 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.2233 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 4/25\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.2010 - sparse_categorical_accuracy: 0.5064 - val_loss: 1.0990 - val_sparse_categorical_accuracy: 0.5677\n",
      "Epoch 5/25\n",
      "97/97 [==============================] - 136s 1s/step - loss: 1.1398 - sparse_categorical_accuracy: 0.5370 - val_loss: 1.0768 - val_sparse_categorical_accuracy: 0.5573\n",
      "Epoch 6/25\n",
      "97/97 [==============================] - 135s 1s/step - loss: 1.1281 - sparse_categorical_accuracy: 0.5522 - val_loss: 1.0613 - val_sparse_categorical_accuracy: 0.5729\n",
      "Epoch 7/25\n",
      "97/97 [==============================] - 137s 1s/step - loss: 1.0861 - sparse_categorical_accuracy: 0.5660 - val_loss: 1.0771 - val_sparse_categorical_accuracy: 0.5443\n",
      "Epoch 8/25\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.0461 - sparse_categorical_accuracy: 0.5889 - val_loss: 1.0003 - val_sparse_categorical_accuracy: 0.6172\n",
      "Epoch 9/25\n",
      "79/97 [=======================>......] - ETA: 17s - loss: 1.0235 - sparse_categorical_accuracy: 0.5989WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2425 batches). You may need to use the repeat() function when building your dataset.\n",
      "97/97 [==============================] - 113s 1s/step - loss: 1.0235 - sparse_categorical_accuracy: 0.5989 - val_loss: 0.9657 - val_sparse_categorical_accuracy: 0.5911\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, \n",
    "                    epochs=25, \n",
    "                    steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                    validation_data=valid_set, \n",
    "                    validation_steps=int(0.9 * max_valid_instance / batch_size),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4883a",
   "metadata": {},
   "source": [
    "### Experiment with Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bab78d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr*self.factor)\n",
    "        \n",
    "def find_learnig_rate(model, train_set, epochs=1, batch_size=32, min_rate=1e-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    iterations = np.math.ceil(0.9*max_train_instance / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(train_set, \n",
    "                        epochs=epochs, \n",
    "                        steps_per_epoch=int(0.9 * max_train_instance / batch_size),\n",
    "                        batch_size=batch_size, \n",
    "                        callbacks=[exp_lr])\n",
    "    model.set_weights(init_weights)\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_rates_vs_losses(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3d95dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8414070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 98s 1s/step - loss: nan - sparse_categorical_accuracy: 0.2342         \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "rates, losses = find_learnig_rate(model, train_set, epochs=1, batch_size=batch_size)\n",
    "plot_rates_vs_losses(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7d069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
