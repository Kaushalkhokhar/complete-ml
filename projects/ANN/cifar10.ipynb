{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790256d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b19a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8b85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83faef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf06a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, y_train_full.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445f3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d1285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 32, 32, 3), (5000, 32, 32, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61131d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\TheCompleteML\\\\projects'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if \"ANN\" in os.path.abspath(os.curdir): os.chdir(\"..\")\n",
    "BASE_DIR = os.path.abspath(os.curdir)\n",
    "BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1264729",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ANN\" not in os.path.abspath(os.curdir): \n",
    "    os.chdir(os.path.abspath(os.path.join(os.curdir, \"ANN\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfae0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "faab1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100, \n",
    "                                kernel_initializer=keras.initializers.he_normal, \n",
    "                                activation=keras.activations.elu))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f136152",
   "metadata": {},
   "source": [
    "#### Learning Rate Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dac34460",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_index = 3 # increment this at every run\n",
    "learning_rate = 2e-5\n",
    "\n",
    "logdir = os.path.join(BASE_DIR, \"logs\", \"dnn_cifar10_logs\")\n",
    "run_logdir = os.path.join(logdir, \"run_{:03d}\".format(run_index))\n",
    "model_path = os.path.join(BASE_DIR, \"models\", f\"{'cifar10_' + str(learning_rate)[2:]}\")\n",
    "\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=20)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e9e2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "             optimizer=keras.optimizers.Nadam(learning_rate=learning_rate), \n",
    "             metrics=keras.metrics.sparse_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9c5c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [model_checkpoint_cb, early_stopping, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a392438",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 6.4350 - sparse_categorical_accuracy: 0.2238- ETA: 2s INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_003\\assets\n",
      "1407/1407 [==============================] - 16s 9ms/step - loss: 6.4350 - sparse_categorical_accuracy: 0.2238 - val_loss: 2.3675 - val_sparse_categorical_accuracy: 0.1874\n",
      "Epoch 2/10\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 2.1500 - sparse_categorical_accuracy: 0.1785INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_003\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 2.1497 - sparse_categorical_accuracy: 0.1786 - val_loss: 2.1194 - val_sparse_categorical_accuracy: 0.1678\n",
      "Epoch 3/10\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 2.0849 - sparse_categorical_accuracy: 0.1827INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_003\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 2.0847 - sparse_categorical_accuracy: 0.1827 - val_loss: 2.0670 - val_sparse_categorical_accuracy: 0.2074\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.0788 - sparse_categorical_accuracy: 0.1863 - val_loss: 2.0909 - val_sparse_categorical_accuracy: 0.1704\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.1571 - sparse_categorical_accuracy: 0.1600 - val_loss: 2.1824 - val_sparse_categorical_accuracy: 0.1544\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.1054 - sparse_categorical_accuracy: 0.1818 - val_loss: 2.2291 - val_sparse_categorical_accuracy: 0.1516\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 3.0138 - sparse_categorical_accuracy: 0.1035 - val_loss: 2.3343 - val_sparse_categorical_accuracy: 0.0970\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.3314 - sparse_categorical_accuracy: 0.0976 - val_loss: 2.3183 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.3289 - sparse_categorical_accuracy: 0.1009 - val_loss: 2.3064 - val_sparse_categorical_accuracy: 0.0994\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.3275 - sparse_categorical_accuracy: 0.1017 - val_loss: 2.3272 - val_sparse_categorical_accuracy: 0.0988\n"
     ]
    }
   ],
   "source": [
    "# # 3e-3\n",
    "# history = model.fit(X_train, y_train, epochs=10, \n",
    "#                     validation_data=(X_valid, y_valid),\n",
    "#                     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2a383be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 3.3942 - sparse_categorical_accuracy: 0.1924- ETA: 2s - lossINFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 16s 9ms/step - loss: 3.3919 - sparse_categorical_accuracy: 0.1924 - val_loss: 2.2258 - val_sparse_categorical_accuracy: 0.2120\n",
      "Epoch 2/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.9892 - sparse_categorical_accuracy: 0.2744INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.9891 - sparse_categorical_accuracy: 0.2744 - val_loss: 2.1193 - val_sparse_categorical_accuracy: 0.2464\n",
      "Epoch 3/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.8888 - sparse_categorical_accuracy: 0.3119INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8888 - sparse_categorical_accuracy: 0.3119 - val_loss: 1.9566 - val_sparse_categorical_accuracy: 0.2984\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.8120 - sparse_categorical_accuracy: 0.3404 - val_loss: 2.0654 - val_sparse_categorical_accuracy: 0.2614\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7658 - sparse_categorical_accuracy: 0.3589 - val_loss: 1.9702 - val_sparse_categorical_accuracy: 0.3074\n",
      "Epoch 6/10\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.7140 - sparse_categorical_accuracy: 0.3791INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7138 - sparse_categorical_accuracy: 0.3792 - val_loss: 1.7081 - val_sparse_categorical_accuracy: 0.3762\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6791 - sparse_categorical_accuracy: 0.3957 - val_loss: 1.7350 - val_sparse_categorical_accuracy: 0.3666\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6458 - sparse_categorical_accuracy: 0.4076 - val_loss: 1.7166 - val_sparse_categorical_accuracy: 0.3868\n",
      "Epoch 9/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.6088 - sparse_categorical_accuracy: 0.4214INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6089 - sparse_categorical_accuracy: 0.4214 - val_loss: 1.6572 - val_sparse_categorical_accuracy: 0.3970\n",
      "Epoch 10/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5878 - sparse_categorical_accuracy: 0.4262INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5877 - sparse_categorical_accuracy: 0.4262 - val_loss: 1.6526 - val_sparse_categorical_accuracy: 0.3932\n"
     ]
    }
   ],
   "source": [
    "# # 1e-4\n",
    "# history = model.fit(X_train, y_train, epochs=10, \n",
    "#                     validation_data=(X_valid, y_valid),\n",
    "#                     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86471c14",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 7.0574 - sparse_categorical_accuracy: 0.1251INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 16s 9ms/step - loss: 7.0371 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.5228 - val_sparse_categorical_accuracy: 0.1766\n",
      "Epoch 2/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 2.2992 - sparse_categorical_accuracy: 0.1876INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 2.2991 - sparse_categorical_accuracy: 0.1876 - val_loss: 2.1739 - val_sparse_categorical_accuracy: 0.2006\n",
      "Epoch 3/10\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 2.1062 - sparse_categorical_accuracy: 0.2289INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 2.1059 - sparse_categorical_accuracy: 0.2290 - val_loss: 2.0708 - val_sparse_categorical_accuracy: 0.2282\n",
      "Epoch 4/10\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 2.0132 - sparse_categorical_accuracy: 0.2610INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 2.0131 - sparse_categorical_accuracy: 0.2612 - val_loss: 2.0115 - val_sparse_categorical_accuracy: 0.2508\n",
      "Epoch 5/10\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.9339 - sparse_categorical_accuracy: 0.2887INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.9338 - sparse_categorical_accuracy: 0.2888 - val_loss: 1.9357 - val_sparse_categorical_accuracy: 0.2848\n",
      "Epoch 6/10\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.8669 - sparse_categorical_accuracy: 0.3151INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8666 - sparse_categorical_accuracy: 0.3154 - val_loss: 1.8837 - val_sparse_categorical_accuracy: 0.3068\n",
      "Epoch 7/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.8191 - sparse_categorical_accuracy: 0.3360INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8190 - sparse_categorical_accuracy: 0.3360 - val_loss: 1.8486 - val_sparse_categorical_accuracy: 0.3208\n",
      "Epoch 8/10\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.7758 - sparse_categorical_accuracy: 0.3509INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7756 - sparse_categorical_accuracy: 0.3508 - val_loss: 1.7876 - val_sparse_categorical_accuracy: 0.3488\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.7337 - sparse_categorical_accuracy: 0.3684INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7337 - sparse_categorical_accuracy: 0.3684 - val_loss: 1.7866 - val_sparse_categorical_accuracy: 0.3504\n",
      "Epoch 10/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.7046 - sparse_categorical_accuracy: 0.3785INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_-05\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7046 - sparse_categorical_accuracy: 0.3784 - val_loss: 1.7486 - val_sparse_categorical_accuracy: 0.3590\n"
     ]
    }
   ],
   "source": [
    "# # 2e-5\n",
    "# history = model.fit(X_train, y_train, epochs=10, \n",
    "#                     validation_data=(X_valid, y_valid),\n",
    "#                     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b248f",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "Learning rate around 1e-4 performs well compare to others, we can also tune it further for more accuracy\n",
    "Let's tune the model to 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bddf63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb1ae8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100, \n",
    "                                kernel_initializer=keras.initializers.he_normal, \n",
    "                                activation=keras.activations.elu))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "run_index = 4 # increment this at every run\n",
    "learning_rate = 1e-4\n",
    "\n",
    "logdir = os.path.join(BASE_DIR, \"logs\", \"dnn_cifar10_logs\")\n",
    "run_logdir = os.path.join(logdir, \"run_{:03d}\".format(run_index))\n",
    "model_path = os.path.join(BASE_DIR, \"models\", f\"{'cifar10_' + str(learning_rate)[2:]}\")\n",
    "\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=20)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "             optimizer=keras.optimizers.Nadam(learning_rate=learning_rate), \n",
    "             metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "\n",
    "callbacks = [model_checkpoint_cb, early_stopping, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea707181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 3.3969 - sparse_categorical_accuracy: 0.1922INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 15s 9ms/step - loss: 3.3919 - sparse_categorical_accuracy: 0.1924 - val_loss: 2.2258 - val_sparse_categorical_accuracy: 0.2120\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.9891 - sparse_categorical_accuracy: 0.2744INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.9891 - sparse_categorical_accuracy: 0.2744 - val_loss: 2.1193 - val_sparse_categorical_accuracy: 0.2464\n",
      "Epoch 3/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.8888 - sparse_categorical_accuracy: 0.3117INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8888 - sparse_categorical_accuracy: 0.3119 - val_loss: 1.9566 - val_sparse_categorical_accuracy: 0.2984\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8120 - sparse_categorical_accuracy: 0.3404 - val_loss: 2.0654 - val_sparse_categorical_accuracy: 0.2614\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7658 - sparse_categorical_accuracy: 0.3589 - val_loss: 1.9702 - val_sparse_categorical_accuracy: 0.3074\n",
      "Epoch 6/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.7137 - sparse_categorical_accuracy: 0.3793INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7138 - sparse_categorical_accuracy: 0.3792 - val_loss: 1.7081 - val_sparse_categorical_accuracy: 0.3762\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6791 - sparse_categorical_accuracy: 0.3957 - val_loss: 1.7350 - val_sparse_categorical_accuracy: 0.3666\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6458 - sparse_categorical_accuracy: 0.4076 - val_loss: 1.7166 - val_sparse_categorical_accuracy: 0.3868\n",
      "Epoch 9/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.6086 - sparse_categorical_accuracy: 0.4216INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6089 - sparse_categorical_accuracy: 0.4214 - val_loss: 1.6572 - val_sparse_categorical_accuracy: 0.3970\n",
      "Epoch 10/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.5876 - sparse_categorical_accuracy: 0.4261INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5877 - sparse_categorical_accuracy: 0.4262 - val_loss: 1.6526 - val_sparse_categorical_accuracy: 0.3932\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5631 - sparse_categorical_accuracy: 0.4392 - val_loss: 1.6528 - val_sparse_categorical_accuracy: 0.4056\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5445 - sparse_categorical_accuracy: 0.4467 - val_loss: 1.7493 - val_sparse_categorical_accuracy: 0.3960\n",
      "Epoch 13/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5247 - sparse_categorical_accuracy: 0.4523INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5247 - sparse_categorical_accuracy: 0.4524 - val_loss: 1.6230 - val_sparse_categorical_accuracy: 0.4188\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5070 - sparse_categorical_accuracy: 0.4580INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5070 - sparse_categorical_accuracy: 0.4580 - val_loss: 1.6188 - val_sparse_categorical_accuracy: 0.4240\n",
      "Epoch 15/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.4949 - sparse_categorical_accuracy: 0.4633- ETA: 0s - loss: 1.4946 - sparse_categorical_accuracyINFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4949 - sparse_categorical_accuracy: 0.4633 - val_loss: 1.5909 - val_sparse_categorical_accuracy: 0.4308\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4752 - sparse_categorical_accuracy: 0.4687 - val_loss: 1.6215 - val_sparse_categorical_accuracy: 0.4138\n",
      "Epoch 17/100\n",
      "1399/1407 [============================>.] - ETA: 0s - loss: 1.4653 - sparse_categorical_accuracy: 0.4719INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.4645 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.5610 - val_sparse_categorical_accuracy: 0.4448\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4505 - sparse_categorical_accuracy: 0.4792 - val_loss: 1.5819 - val_sparse_categorical_accuracy: 0.4320\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.4400 - sparse_categorical_accuracy: 0.4844INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.4400 - sparse_categorical_accuracy: 0.4844 - val_loss: 1.5471 - val_sparse_categorical_accuracy: 0.4400\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4240 - sparse_categorical_accuracy: 0.4890 - val_loss: 1.5947 - val_sparse_categorical_accuracy: 0.4294\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4149 - sparse_categorical_accuracy: 0.4912 - val_loss: 1.5486 - val_sparse_categorical_accuracy: 0.4558\n",
      "Epoch 22/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.4012 - sparse_categorical_accuracy: 0.4976INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4008 - sparse_categorical_accuracy: 0.4978 - val_loss: 1.5443 - val_sparse_categorical_accuracy: 0.4512\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.3894 - sparse_categorical_accuracy: 0.5033 - val_loss: 1.5986 - val_sparse_categorical_accuracy: 0.4338\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3781 - sparse_categorical_accuracy: 0.5057 - val_loss: 1.5626 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3659 - sparse_categorical_accuracy: 0.5106 - val_loss: 1.5773 - val_sparse_categorical_accuracy: 0.4448\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3571 - sparse_categorical_accuracy: 0.5133 - val_loss: 1.5772 - val_sparse_categorical_accuracy: 0.4498rse_categorical_accuracy: 0.513\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3480 - sparse_categorical_accuracy: 0.5158 - val_loss: 1.5772 - val_sparse_categorical_accuracy: 0.4456\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3360 - sparse_categorical_accuracy: 0.5211 - val_loss: 1.5741 - val_sparse_categorical_accuracy: 0.4564\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3285 - sparse_categorical_accuracy: 0.5235 - val_loss: 1.5462 - val_sparse_categorical_accuracy: 0.4600\n",
      "Epoch 30/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.3178 - sparse_categorical_accuracy: 0.5273- ETA: 2s - loss: 1.314INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.3182 - sparse_categorical_accuracy: 0.5272 - val_loss: 1.5415 - val_sparse_categorical_accuracy: 0.4600\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3074 - sparse_categorical_accuracy: 0.5283 - val_loss: 1.5743 - val_sparse_categorical_accuracy: 0.4516\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2952 - sparse_categorical_accuracy: 0.5343 - val_loss: 1.5704 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2894 - sparse_categorical_accuracy: 0.5370 - val_loss: 1.5472 - val_sparse_categorical_accuracy: 0.4582\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.2784 - sparse_categorical_accuracy: 0.5407INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2784 - sparse_categorical_accuracy: 0.5407 - val_loss: 1.5362 - val_sparse_categorical_accuracy: 0.4618\n",
      "Epoch 35/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.2700 - sparse_categorical_accuracy: 0.5438INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2701 - sparse_categorical_accuracy: 0.5438 - val_loss: 1.5353 - val_sparse_categorical_accuracy: 0.4636\n",
      "Epoch 36/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.2609 - sparse_categorical_accuracy: 0.5472- ETA: 3s - loss: 1. - ETA: 1s - loss: 1.2619 - sparse_categorINFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2606 - sparse_categorical_accuracy: 0.5474 - val_loss: 1.5315 - val_sparse_categorical_accuracy: 0.4730\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2515 - sparse_categorical_accuracy: 0.5527 - val_loss: 1.6147 - val_sparse_categorical_accuracy: 0.4562\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2442 - sparse_categorical_accuracy: 0.5548 - val_loss: 1.5531 - val_sparse_categorical_accuracy: 0.4684\n",
      "Epoch 39/100\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 1.2384 - sparse_categorical_accuracy: 0.5571INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2390 - sparse_categorical_accuracy: 0.5570 - val_loss: 1.5295 - val_sparse_categorical_accuracy: 0.4706\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2315 - sparse_categorical_accuracy: 0.5564 - val_loss: 1.5399 - val_sparse_categorical_accuracy: 0.4726\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2168 - sparse_categorical_accuracy: 0.5625 - val_loss: 1.5545 - val_sparse_categorical_accuracy: 0.4746\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2097 - sparse_categorical_accuracy: 0.5657 - val_loss: 1.5863 - val_sparse_categorical_accuracy: 0.4604\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2047 - sparse_categorical_accuracy: 0.5685 - val_loss: 1.5479 - val_sparse_categorical_accuracy: 0.4662\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1908 - sparse_categorical_accuracy: 0.5726 - val_loss: 1.5351 - val_sparse_categorical_accuracy: 0.4688\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1855 - sparse_categorical_accuracy: 0.5734 - val_loss: 1.5605 - val_sparse_categorical_accuracy: 0.4636\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1790 - sparse_categorical_accuracy: 0.5750 - val_loss: 1.6034 - val_sparse_categorical_accuracy: 0.4566\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1743 - sparse_categorical_accuracy: 0.5788 - val_loss: 1.5807 - val_sparse_categorical_accuracy: 0.4690\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1642 - sparse_categorical_accuracy: 0.5810 - val_loss: 1.5824 - val_sparse_categorical_accuracy: 0.4662\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1576 - sparse_categorical_accuracy: 0.5840 - val_loss: 1.6002 - val_sparse_categorical_accuracy: 0.4630\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1497 - sparse_categorical_accuracy: 0.5859 - val_loss: 1.6018 - val_sparse_categorical_accuracy: 0.4658\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1391 - sparse_categorical_accuracy: 0.5888 - val_loss: 1.5895 - val_sparse_categorical_accuracy: 0.4606\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1314 - sparse_categorical_accuracy: 0.5938 - val_loss: 1.6005 - val_sparse_categorical_accuracy: 0.4642\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1248 - sparse_categorical_accuracy: 0.5980 - val_loss: 1.6259 - val_sparse_categorical_accuracy: 0.4652\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1179 - sparse_categorical_accuracy: 0.5970 - val_loss: 1.5975 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1099 - sparse_categorical_accuracy: 0.5992 - val_loss: 1.5887 - val_sparse_categorical_accuracy: 0.4724\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1050 - sparse_categorical_accuracy: 0.6045 - val_loss: 1.6116 - val_sparse_categorical_accuracy: 0.4726\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0975 - sparse_categorical_accuracy: 0.6064 - val_loss: 1.6451 - val_sparse_categorical_accuracy: 0.4722\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0915 - sparse_categorical_accuracy: 0.6084 - val_loss: 1.5683 - val_sparse_categorical_accuracy: 0.4796\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0835 - sparse_categorical_accuracy: 0.6121 - val_loss: 1.6417 - val_sparse_categorical_accuracy: 0.4684\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4421a3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 1.5295 - sparse_categorical_accuracy: 0.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5294785499572754, 0.4706000089645386]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(model_path)\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c98ec",
   "metadata": {},
   "source": [
    "### Batch Normalizaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8e44216",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(activation=\"elu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "learnig_rate = 5e-4 # we can fine tune on 10 to 20 epochs based on time\n",
    "train_count = 1 # update on each train\n",
    "\n",
    "logdir = os.path.join(BASE_DIR, \"logs\", \"dnn_cifar10_logs\")\n",
    "run_logdir = os.path.join(logdir, \"run_{:03d}\".format(train_count))\n",
    "model_path = os.path.join(BASE_DIR, \"models\", f\"{'cifar10_batch_'+str(learning_rate)[2:]}\")\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Nadam(learning_rate=learnig_rate),\n",
    "              metrics=keras.metrics.sparse_categorical_accuracy)\n",
    "\n",
    "modelcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)\n",
    "earlystoping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint_cb, early_stopping, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbedab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 26s 12ms/step - loss: 1.8292 - sparse_categorical_accuracy: 0.3465 - val_loss: 1.6738 - val_sparse_categorical_accuracy: 0.3984\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.6656 - sparse_categorical_accuracy: 0.4074 - val_loss: 1.6008 - val_sparse_categorical_accuracy: 0.4328\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5937 - sparse_categorical_accuracy: 0.4329 - val_loss: 1.5522 - val_sparse_categorical_accuracy: 0.4452\n",
      "Epoch 4/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.5430 - sparse_categorical_accuracy: 0.4502INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.5428 - sparse_categorical_accuracy: 0.4503 - val_loss: 1.5263 - val_sparse_categorical_accuracy: 0.4496\n",
      "Epoch 5/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.5007 - sparse_categorical_accuracy: 0.4637INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.5008 - sparse_categorical_accuracy: 0.4638 - val_loss: 1.5080 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 6/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4615 - sparse_categorical_accuracy: 0.4819INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.4616 - sparse_categorical_accuracy: 0.4819 - val_loss: 1.4754 - val_sparse_categorical_accuracy: 0.4738\n",
      "Epoch 7/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.4268 - sparse_categorical_accuracy: 0.4931INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.4267 - sparse_categorical_accuracy: 0.4932 - val_loss: 1.4588 - val_sparse_categorical_accuracy: 0.4826\n",
      "Epoch 8/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.4043 - sparse_categorical_accuracy: 0.5011INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.4042 - sparse_categorical_accuracy: 0.5012 - val_loss: 1.4377 - val_sparse_categorical_accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3742 - sparse_categorical_accuracy: 0.5154 - val_loss: 1.4405 - val_sparse_categorical_accuracy: 0.4866\n",
      "Epoch 10/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3557 - sparse_categorical_accuracy: 0.5197INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.3555 - sparse_categorical_accuracy: 0.5198 - val_loss: 1.4343 - val_sparse_categorical_accuracy: 0.4926\n",
      "Epoch 11/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.3325 - sparse_categorical_accuracy: 0.5282INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.3327 - sparse_categorical_accuracy: 0.5282 - val_loss: 1.3969 - val_sparse_categorical_accuracy: 0.5076\n",
      "Epoch 12/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.3185 - sparse_categorical_accuracy: 0.5318INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.3185 - sparse_categorical_accuracy: 0.5318 - val_loss: 1.3950 - val_sparse_categorical_accuracy: 0.5110\n",
      "Epoch 13/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.2947 - sparse_categorical_accuracy: 0.5389INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2946 - sparse_categorical_accuracy: 0.5389 - val_loss: 1.3872 - val_sparse_categorical_accuracy: 0.5176\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2742 - sparse_categorical_accuracy: 0.5506 - val_loss: 1.3993 - val_sparse_categorical_accuracy: 0.5156\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2599 - sparse_categorical_accuracy: 0.5498 - val_loss: 1.4032 - val_sparse_categorical_accuracy: 0.5102\n",
      "Epoch 16/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.2397 - sparse_categorical_accuracy: 0.5604INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.2397 - sparse_categorical_accuracy: 0.5604 - val_loss: 1.3658 - val_sparse_categorical_accuracy: 0.5254\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2302 - sparse_categorical_accuracy: 0.5662 - val_loss: 1.3942 - val_sparse_categorical_accuracy: 0.5110\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2108 - sparse_categorical_accuracy: 0.5728 - val_loss: 1.3842 - val_sparse_categorical_accuracy: 0.5142\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1939 - sparse_categorical_accuracy: 0.5793 - val_loss: 1.3715 - val_sparse_categorical_accuracy: 0.5224\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1817 - sparse_categorical_accuracy: 0.5819 - val_loss: 1.3990 - val_sparse_categorical_accuracy: 0.5176\n",
      "Epoch 21/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.1623 - sparse_categorical_accuracy: 0.5882INFO:tensorflow:Assets written to: D:\\TheCompleteML\\projects\\models\\cifar10_0001\\assets\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.1625 - sparse_categorical_accuracy: 0.5882 - val_loss: 1.3594 - val_sparse_categorical_accuracy: 0.5316\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 1.1556 - sparse_categorical_accuracy: 0.5929 - val_loss: 1.4011 - val_sparse_categorical_accuracy: 0.5110\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1391 - sparse_categorical_accuracy: 0.5979 - val_loss: 1.3858 - val_sparse_categorical_accuracy: 0.5252\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1267 - sparse_categorical_accuracy: 0.6035 - val_loss: 1.3609 - val_sparse_categorical_accuracy: 0.5364\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1245 - sparse_categorical_accuracy: 0.6008 - val_loss: 1.4060 - val_sparse_categorical_accuracy: 0.5164\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1088 - sparse_categorical_accuracy: 0.6096 - val_loss: 1.3948 - val_sparse_categorical_accuracy: 0.5248\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1036 - sparse_categorical_accuracy: 0.6110 - val_loss: 1.3916 - val_sparse_categorical_accuracy: 0.5204\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0872 - sparse_categorical_accuracy: 0.6133 - val_loss: 1.3938 - val_sparse_categorical_accuracy: 0.5306\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0710 - sparse_categorical_accuracy: 0.6222 - val_loss: 1.3866 - val_sparse_categorical_accuracy: 0.5278\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0640 - sparse_categorical_accuracy: 0.6219 - val_loss: 1.3965 - val_sparse_categorical_accuracy: 0.5244\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0508 - sparse_categorical_accuracy: 0.6286 - val_loss: 1.3724 - val_sparse_categorical_accuracy: 0.5374\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0444 - sparse_categorical_accuracy: 0.6322 - val_loss: 1.4089 - val_sparse_categorical_accuracy: 0.5280\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0343 - sparse_categorical_accuracy: 0.6381 - val_loss: 1.3678 - val_sparse_categorical_accuracy: 0.5346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0220 - sparse_categorical_accuracy: 0.6408 - val_loss: 1.3975 - val_sparse_categorical_accuracy: 0.5296\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0105 - sparse_categorical_accuracy: 0.6435 - val_loss: 1.4120 - val_sparse_categorical_accuracy: 0.5232\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0049 - sparse_categorical_accuracy: 0.6452 - val_loss: 1.4133 - val_sparse_categorical_accuracy: 0.5248\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9952 - sparse_categorical_accuracy: 0.6473 - val_loss: 1.4214 - val_sparse_categorical_accuracy: 0.5292\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9766 - sparse_categorical_accuracy: 0.6563 - val_loss: 1.4079 - val_sparse_categorical_accuracy: 0.5368\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9789 - sparse_categorical_accuracy: 0.6547 - val_loss: 1.4413 - val_sparse_categorical_accuracy: 0.5148\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9697 - sparse_categorical_accuracy: 0.6576 - val_loss: 1.4291 - val_sparse_categorical_accuracy: 0.5278\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9698 - sparse_categorical_accuracy: 0.6567 - val_loss: 1.3990 - val_sparse_categorical_accuracy: 0.5334\n"
     ]
    }
   ],
   "source": [
    "histroy = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfce01",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "as due to batch normalization it takes more time per epoch but it converges much faster then the noramal method, 50% validations accuracy achieved in 12 epochs and same was in 60 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d4e5b",
   "metadata": {},
   "source": [
    "### Implementing SELU as activations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c883d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(-1, 32, 32, 3)\n",
    "X_valid_scaled = scaler.transform(X_valid.reshape(-1, 1)).reshape(-1, 32, 32, 3)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, 1)).reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b71dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b23ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a65885f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"selu\",\n",
    "                                 kernel_initializer=keras.initializers.lecun_normal))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce8be226",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Nadam(learning_rate=7e-4), # we can tune for learning rate for 10 to 20 epochs\n",
    "             metrics=keras.metrics.sparse_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19381e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[keras.callbacks.EarlyStopping(patience=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ed52ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 14s 8ms/step - loss: 1.9222 - sparse_categorical_accuracy: 0.3138 - val_loss: 1.8392 - val_sparse_categorical_accuracy: 0.3484\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7126 - sparse_categorical_accuracy: 0.3942 - val_loss: 1.7876 - val_sparse_categorical_accuracy: 0.3696\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6177 - sparse_categorical_accuracy: 0.4282 - val_loss: 1.6275 - val_sparse_categorical_accuracy: 0.4260\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5495 - sparse_categorical_accuracy: 0.4555 - val_loss: 1.6281 - val_sparse_categorical_accuracy: 0.4082\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4936 - sparse_categorical_accuracy: 0.4768 - val_loss: 1.6068 - val_sparse_categorical_accuracy: 0.4218\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4423 - sparse_categorical_accuracy: 0.4970 - val_loss: 1.5946 - val_sparse_categorical_accuracy: 0.4522\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4030 - sparse_categorical_accuracy: 0.5078 - val_loss: 1.5663 - val_sparse_categorical_accuracy: 0.4634\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3686 - sparse_categorical_accuracy: 0.5230 - val_loss: 1.5306 - val_sparse_categorical_accuracy: 0.4764\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3280 - sparse_categorical_accuracy: 0.5377 - val_loss: 1.5450 - val_sparse_categorical_accuracy: 0.4786\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3042 - sparse_categorical_accuracy: 0.5443 - val_loss: 1.5782 - val_sparse_categorical_accuracy: 0.4722\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2680 - sparse_categorical_accuracy: 0.5574 - val_loss: 1.5331 - val_sparse_categorical_accuracy: 0.4830\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2426 - sparse_categorical_accuracy: 0.5667 - val_loss: 1.5283 - val_sparse_categorical_accuracy: 0.4734\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2133 - sparse_categorical_accuracy: 0.5810 - val_loss: 1.5257 - val_sparse_categorical_accuracy: 0.4934\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1861 - sparse_categorical_accuracy: 0.5903 - val_loss: 1.5533 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1788 - sparse_categorical_accuracy: 0.5918 - val_loss: 1.5052 - val_sparse_categorical_accuracy: 0.4956\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1433 - sparse_categorical_accuracy: 0.6054 - val_loss: 1.5591 - val_sparse_categorical_accuracy: 0.4962\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1240 - sparse_categorical_accuracy: 0.6100 - val_loss: 1.5580 - val_sparse_categorical_accuracy: 0.4890\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1127 - sparse_categorical_accuracy: 0.6179 - val_loss: 1.5865 - val_sparse_categorical_accuracy: 0.4806\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0861 - sparse_categorical_accuracy: 0.6258 - val_loss: 1.5294 - val_sparse_categorical_accuracy: 0.4854\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0757 - sparse_categorical_accuracy: 0.6290 - val_loss: 1.5456 - val_sparse_categorical_accuracy: 0.4940\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0506 - sparse_categorical_accuracy: 0.6412 - val_loss: 1.5350 - val_sparse_categorical_accuracy: 0.4960\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0365 - sparse_categorical_accuracy: 0.6446 - val_loss: 1.5719 - val_sparse_categorical_accuracy: 0.4892\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0094 - sparse_categorical_accuracy: 0.6553 - val_loss: 1.5877 - val_sparse_categorical_accuracy: 0.5056\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0133 - sparse_categorical_accuracy: 0.6554 - val_loss: 1.6266 - val_sparse_categorical_accuracy: 0.4930\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9881 - sparse_categorical_accuracy: 0.6636 - val_loss: 1.6458 - val_sparse_categorical_accuracy: 0.4880\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7150 - sparse_categorical_accuracy: 0.6167 - val_loss: 1.6315 - val_sparse_categorical_accuracy: 0.4386\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2432 - sparse_categorical_accuracy: 0.5679 - val_loss: 1.5751 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1346 - sparse_categorical_accuracy: 0.6090 - val_loss: 1.6068 - val_sparse_categorical_accuracy: 0.4814\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0641 - sparse_categorical_accuracy: 0.6336 - val_loss: 1.6032 - val_sparse_categorical_accuracy: 0.4942\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0189 - sparse_categorical_accuracy: 0.6499 - val_loss: 1.5930 - val_sparse_categorical_accuracy: 0.4984\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9733 - sparse_categorical_accuracy: 0.6663 - val_loss: 1.6257 - val_sparse_categorical_accuracy: 0.5052\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 5.6701 - sparse_categorical_accuracy: 0.5714 - val_loss: 1.7136 - val_sparse_categorical_accuracy: 0.3946\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3918 - sparse_categorical_accuracy: 0.5096 - val_loss: 1.6624 - val_sparse_categorical_accuracy: 0.4308\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2802 - sparse_categorical_accuracy: 0.5475 - val_loss: 1.6337 - val_sparse_categorical_accuracy: 0.4582\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2138 - sparse_categorical_accuracy: 0.5747 - val_loss: 1.5974 - val_sparse_categorical_accuracy: 0.4682\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1710 - sparse_categorical_accuracy: 0.5926 - val_loss: 1.5916 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1647 - sparse_categorical_accuracy: 0.6005 - val_loss: 1.6121 - val_sparse_categorical_accuracy: 0.4648\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1514 - sparse_categorical_accuracy: 0.5997 - val_loss: 1.6193 - val_sparse_categorical_accuracy: 0.4822\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0939 - sparse_categorical_accuracy: 0.6210 - val_loss: 1.6022 - val_sparse_categorical_accuracy: 0.4792\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0751 - sparse_categorical_accuracy: 0.6261 - val_loss: 1.6129 - val_sparse_categorical_accuracy: 0.4796\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0522 - sparse_categorical_accuracy: 0.6367 - val_loss: 1.6010 - val_sparse_categorical_accuracy: 0.4830\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0322 - sparse_categorical_accuracy: 0.6441 - val_loss: 1.6007 - val_sparse_categorical_accuracy: 0.4912\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.0155 - sparse_categorical_accuracy: 0.6500 - val_loss: 1.6767 - val_sparse_categorical_accuracy: 0.4904\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9869 - sparse_categorical_accuracy: 0.6631 - val_loss: 1.6276 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9589 - sparse_categorical_accuracy: 0.6704 - val_loss: 1.6091 - val_sparse_categorical_accuracy: 0.4964\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9420 - sparse_categorical_accuracy: 0.6791 - val_loss: 1.6018 - val_sparse_categorical_accuracy: 0.5038\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9289 - sparse_categorical_accuracy: 0.6845 - val_loss: 1.6789 - val_sparse_categorical_accuracy: 0.4840\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9074 - sparse_categorical_accuracy: 0.6916 - val_loss: 1.6423 - val_sparse_categorical_accuracy: 0.5052\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8995 - sparse_categorical_accuracy: 0.6916 - val_loss: 1.6404 - val_sparse_categorical_accuracy: 0.4892\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8725 - sparse_categorical_accuracy: 0.7021 - val_loss: 1.7083 - val_sparse_categorical_accuracy: 0.5010\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8608 - sparse_categorical_accuracy: 0.7077 - val_loss: 1.8163 - val_sparse_categorical_accuracy: 0.4988\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8381 - sparse_categorical_accuracy: 0.7156 - val_loss: 1.7780 - val_sparse_categorical_accuracy: 0.4910\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8325 - sparse_categorical_accuracy: 0.7190 - val_loss: 1.6873 - val_sparse_categorical_accuracy: 0.5074\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5272 - sparse_categorical_accuracy: 0.7128 - val_loss: 2.2401 - val_sparse_categorical_accuracy: 0.4810\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0237 - sparse_categorical_accuracy: 0.6486 - val_loss: 1.6887 - val_sparse_categorical_accuracy: 0.4996\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9814 - sparse_categorical_accuracy: 0.6715 - val_loss: 1.6315 - val_sparse_categorical_accuracy: 0.4956\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8703 - sparse_categorical_accuracy: 0.6992 - val_loss: 1.7176 - val_sparse_categorical_accuracy: 0.4994\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8066 - sparse_categorical_accuracy: 0.7238 - val_loss: 1.7527 - val_sparse_categorical_accuracy: 0.5040\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7709 - sparse_categorical_accuracy: 0.7386 - val_loss: 1.7744 - val_sparse_categorical_accuracy: 0.5044\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7541 - sparse_categorical_accuracy: 0.7438 - val_loss: 1.8896 - val_sparse_categorical_accuracy: 0.5040\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7403 - sparse_categorical_accuracy: 0.7475 - val_loss: 1.8733 - val_sparse_categorical_accuracy: 0.5014\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7403 - sparse_categorical_accuracy: 0.7508 - val_loss: 1.9931 - val_sparse_categorical_accuracy: 0.4992\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7404 - sparse_categorical_accuracy: 0.7499 - val_loss: 1.9641 - val_sparse_categorical_accuracy: 0.4946\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7472 - sparse_categorical_accuracy: 0.7490 - val_loss: 1.8610 - val_sparse_categorical_accuracy: 0.5020\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7317 - sparse_categorical_accuracy: 0.7547 - val_loss: 1.8808 - val_sparse_categorical_accuracy: 0.4986\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7268 - sparse_categorical_accuracy: 0.7566 - val_loss: 1.8806 - val_sparse_categorical_accuracy: 0.4978\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7233 - sparse_categorical_accuracy: 0.7554 - val_loss: 1.8948 - val_sparse_categorical_accuracy: 0.4998\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7167 - sparse_categorical_accuracy: 0.7568 - val_loss: 1.9627 - val_sparse_categorical_accuracy: 0.5094\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7004 - sparse_categorical_accuracy: 0.7649 - val_loss: 1.7950 - val_sparse_categorical_accuracy: 0.5048\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7659 - val_loss: 1.8708 - val_sparse_categorical_accuracy: 0.4882\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6837 - sparse_categorical_accuracy: 0.7723 - val_loss: 1.9802 - val_sparse_categorical_accuracy: 0.4932\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6784 - sparse_categorical_accuracy: 0.7741 - val_loss: 1.9331 - val_sparse_categorical_accuracy: 0.4986\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.7771 - val_loss: 2.0247 - val_sparse_categorical_accuracy: 0.5022\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.7794 - val_loss: 1.9060 - val_sparse_categorical_accuracy: 0.4834\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6494 - sparse_categorical_accuracy: 0.7821 - val_loss: 1.9696 - val_sparse_categorical_accuracy: 0.4998\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.7836 - val_loss: 2.0300 - val_sparse_categorical_accuracy: 0.4900\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6319 - sparse_categorical_accuracy: 0.7888 - val_loss: 1.9927 - val_sparse_categorical_accuracy: 0.5012\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6303 - sparse_categorical_accuracy: 0.7906 - val_loss: 1.9904 - val_sparse_categorical_accuracy: 0.4928\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.7890 - val_loss: 2.0873 - val_sparse_categorical_accuracy: 0.5016\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6214 - sparse_categorical_accuracy: 0.7920 - val_loss: 1.9851 - val_sparse_categorical_accuracy: 0.4992\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5993 - sparse_categorical_accuracy: 0.7998 - val_loss: 2.1264 - val_sparse_categorical_accuracy: 0.4980\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9264 - sparse_categorical_accuracy: 0.7098 - val_loss: 1.8447 - val_sparse_categorical_accuracy: 0.4988\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7082 - sparse_categorical_accuracy: 0.7621 - val_loss: 1.9767 - val_sparse_categorical_accuracy: 0.4986\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6490 - sparse_categorical_accuracy: 0.7841 - val_loss: 2.0893 - val_sparse_categorical_accuracy: 0.4960\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5928 - sparse_categorical_accuracy: 0.8026 - val_loss: 2.0565 - val_sparse_categorical_accuracy: 0.4992\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5694 - sparse_categorical_accuracy: 0.8100 - val_loss: 2.1249 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5698 - sparse_categorical_accuracy: 0.8116 - val_loss: 2.2903 - val_sparse_categorical_accuracy: 0.5018\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.5839 - sparse_categorical_accuracy: 0.8068 - val_loss: 2.0906 - val_sparse_categorical_accuracy: 0.4924\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5613 - sparse_categorical_accuracy: 0.8126 - val_loss: 2.4398 - val_sparse_categorical_accuracy: 0.4898\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.5697 - sparse_categorical_accuracy: 0.8130 - val_loss: 2.2557 - val_sparse_categorical_accuracy: 0.5010\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.5698 - sparse_categorical_accuracy: 0.8124 - val_loss: 2.1950 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2792 - sparse_categorical_accuracy: 0.7607 - val_loss: 1.9420 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7718 - val_loss: 1.9997 - val_sparse_categorical_accuracy: 0.4882\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6407 - sparse_categorical_accuracy: 0.7873 - val_loss: 2.0258 - val_sparse_categorical_accuracy: 0.4924\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6067 - sparse_categorical_accuracy: 0.8001 - val_loss: 2.1403 - val_sparse_categorical_accuracy: 0.4972\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.8084 - val_loss: 2.1850 - val_sparse_categorical_accuracy: 0.4960\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5509 - sparse_categorical_accuracy: 0.8184 - val_loss: 2.2465 - val_sparse_categorical_accuracy: 0.4932\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.8210 - val_loss: 2.1775 - val_sparse_categorical_accuracy: 0.4978\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5290 - sparse_categorical_accuracy: 0.8251 - val_loss: 2.2603 - val_sparse_categorical_accuracy: 0.4924\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.8230 - val_loss: 2.1293 - val_sparse_categorical_accuracy: 0.4948\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, validation_data=(X_valid, y_valid), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac2696c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, \n",
    "                                activation=\"selu\",\n",
    "                                kernel_initializer=\"lecun_normal\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "learnig_rate = 5e-4\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Nadam(learning_rate=learnig_rate),\n",
    "             metrics=keras.metrics.sparse_categorical_accuracy)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f635b1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 14s 7ms/step - loss: 1.8782 - sparse_categorical_accuracy: 0.3331 - val_loss: 1.7532 - val_sparse_categorical_accuracy: 0.3680\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6598 - sparse_categorical_accuracy: 0.4125 - val_loss: 1.7109 - val_sparse_categorical_accuracy: 0.4134\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5745 - sparse_categorical_accuracy: 0.4436 - val_loss: 1.6270 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5056 - sparse_categorical_accuracy: 0.4737 - val_loss: 1.5985 - val_sparse_categorical_accuracy: 0.4482\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4499 - sparse_categorical_accuracy: 0.4920 - val_loss: 1.5411 - val_sparse_categorical_accuracy: 0.4626\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4058 - sparse_categorical_accuracy: 0.5080 - val_loss: 1.5527 - val_sparse_categorical_accuracy: 0.4634\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3623 - sparse_categorical_accuracy: 0.5266 - val_loss: 1.5325 - val_sparse_categorical_accuracy: 0.4814\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3260 - sparse_categorical_accuracy: 0.5405 - val_loss: 1.5831 - val_sparse_categorical_accuracy: 0.4674\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2927 - sparse_categorical_accuracy: 0.5528 - val_loss: 1.5379 - val_sparse_categorical_accuracy: 0.4950\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2512 - sparse_categorical_accuracy: 0.5631 - val_loss: 1.5293 - val_sparse_categorical_accuracy: 0.4874\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2197 - sparse_categorical_accuracy: 0.5778 - val_loss: 1.5572 - val_sparse_categorical_accuracy: 0.4964\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1919 - sparse_categorical_accuracy: 0.5856 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.4850\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1675 - sparse_categorical_accuracy: 0.5960 - val_loss: 1.5541 - val_sparse_categorical_accuracy: 0.4990\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1375 - sparse_categorical_accuracy: 0.6079 - val_loss: 1.5806 - val_sparse_categorical_accuracy: 0.4950\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1067 - sparse_categorical_accuracy: 0.6189 - val_loss: 1.6566 - val_sparse_categorical_accuracy: 0.4946\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0868 - sparse_categorical_accuracy: 0.6267 - val_loss: 1.6233 - val_sparse_categorical_accuracy: 0.4982\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0685 - sparse_categorical_accuracy: 0.6336 - val_loss: 1.5877 - val_sparse_categorical_accuracy: 0.5030\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0396 - sparse_categorical_accuracy: 0.6445 - val_loss: 1.6140 - val_sparse_categorical_accuracy: 0.4976\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0184 - sparse_categorical_accuracy: 0.6518 - val_loss: 1.6960 - val_sparse_categorical_accuracy: 0.4964\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9988 - sparse_categorical_accuracy: 0.6584 - val_loss: 1.7635 - val_sparse_categorical_accuracy: 0.5016\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9808 - sparse_categorical_accuracy: 0.6637 - val_loss: 1.7209 - val_sparse_categorical_accuracy: 0.5076\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9606 - sparse_categorical_accuracy: 0.6747 - val_loss: 1.7181 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9384 - sparse_categorical_accuracy: 0.6828 - val_loss: 1.7938 - val_sparse_categorical_accuracy: 0.4926\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9246 - sparse_categorical_accuracy: 0.6865 - val_loss: 1.8265 - val_sparse_categorical_accuracy: 0.5066\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 0.9064 - sparse_categorical_accuracy: 0.6926 - val_loss: 1.8091 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8941 - sparse_categorical_accuracy: 0.6988 - val_loss: 1.7630 - val_sparse_categorical_accuracy: 0.5054\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8786 - sparse_categorical_accuracy: 0.7038 - val_loss: 1.7026 - val_sparse_categorical_accuracy: 0.4974\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8611 - sparse_categorical_accuracy: 0.7105 - val_loss: 1.8340 - val_sparse_categorical_accuracy: 0.4930\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8435 - sparse_categorical_accuracy: 0.7148 - val_loss: 1.8919 - val_sparse_categorical_accuracy: 0.5094\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8290 - sparse_categorical_accuracy: 0.7204 - val_loss: 1.8415 - val_sparse_categorical_accuracy: 0.5120\n"
     ]
    }
   ],
   "source": [
    "callbacks = keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, \n",
    "                    validation_data=(X_valid_scaled, y_valid), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17ca0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = os.path.join(BASE_DIR, \"dnn_with_dropout_with_selu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7399f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fab945aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "239c0a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10000, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fd389cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7f77492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c612143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09, 0.01, 0.1 , 0.27, 0.16, 0.26, 0.02, 0.06, 0.02, 0.01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d8df087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88dd6b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1 , 0.01, 0.11, 0.24, 0.16, 0.23, 0.03, 0.07, 0.03, 0.01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_prob[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34efb518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.core.flatten.Flatten'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n",
      "<class 'keras.layers.noise.AlphaDropout'>\n",
      "<class 'keras.layers.core.dense.Dense'>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(type(layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e825ff",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "here we get 51% accuracy which is good then without the dropout, we can do more tuning with learning rate and drop-out ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3746965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropouts(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d89d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "49c77dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = keras.models.Sequential([MCDropouts(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else \\\n",
    "                                layer for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b65f70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "953920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dropout_probas(model, X, n_samples=10):\n",
    "    y_probas = [model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(y_probas, axis=0)\n",
    "\n",
    "def find_dropout_classes(model, X, n_samples=10):\n",
    "    y_prob = find_dropout_probas(model, X, n_samples)\n",
    "    return np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e2cc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# y_probas = find_dropout_probas(my_model, X_test_scaled, 10)\n",
    "y_pred = find_dropout_classes(my_model, X_valid_scaled, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20a3f268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5124"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_valid[:, 0] == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab2181",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "here we get same accuracy as previous around 51.20 on validation set. Batch normalization has quite good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1fc0dd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.321928094887362"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2c6e213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr*self.factor)\n",
    "        \n",
    "def find_learnig_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    iterations = np.math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=[exp_lr])\n",
    "    model.set_weights(init_weights)\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_rates_vs_losses(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b8977aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c4c6f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "    \n",
    "model.add(keras.layers.AlphaDropout(0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "learning_rate = 1e-3\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "             optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "536f588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 4s 9ms/step - loss: nan - accuracy: 0.1338\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learnig_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_rates_vs_losses(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ed02e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c79a487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 5s 10ms/step - loss: 2.0403 - accuracy: 0.2908 - val_loss: 1.8399 - val_accuracy: 0.3454\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.7609 - accuracy: 0.3777 - val_loss: 1.6631 - val_accuracy: 0.4176\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.6300 - accuracy: 0.4212 - val_loss: 1.6913 - val_accuracy: 0.4072\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.5562 - accuracy: 0.4495 - val_loss: 1.6053 - val_accuracy: 0.4300\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.5007 - accuracy: 0.4691 - val_loss: 1.6516 - val_accuracy: 0.4464\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4626 - accuracy: 0.4822 - val_loss: 1.6092 - val_accuracy: 0.4464\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4321 - accuracy: 0.4920 - val_loss: 1.6340 - val_accuracy: 0.4420\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.3639 - accuracy: 0.5164 - val_loss: 1.5893 - val_accuracy: 0.4688\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2913 - accuracy: 0.5417 - val_loss: 1.5549 - val_accuracy: 0.4868\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2202 - accuracy: 0.5656 - val_loss: 1.5544 - val_accuracy: 0.4938\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1524 - accuracy: 0.5885 - val_loss: 1.5030 - val_accuracy: 0.5042\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0860 - accuracy: 0.6154 - val_loss: 1.5312 - val_accuracy: 0.5084\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0155 - accuracy: 0.6380 - val_loss: 1.5341 - val_accuracy: 0.5144\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9531 - accuracy: 0.6594 - val_loss: 1.5601 - val_accuracy: 0.5208\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9158 - accuracy: 0.6758 - val_loss: 1.5732 - val_accuracy: 0.5212\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4736a5",
   "metadata": {},
   "source": [
    "One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 47.6% to 52.0%). The batch normalized model reaches a slightly better performance (54%), but it's much slower to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2251b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79cf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fecb31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db7884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef481731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
